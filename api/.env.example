# Ollama Configuration
OLLAMA_MODEL=llama3.2:1b
OLLAMA_API_KEY=""
OLLAMA_BASE_URL=http://localhost:11434 ``
OLLAMA_TEMPERATURE=0.7

# Vector Store Configuration
CHROMA_PERSIST_DIR=./chroma_db
CHROMA_COLLECTION_NAME=wiki_docs

# Embeddings Configuration
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
EMBEDDING_DEVICE=cpu

# RAG Configuration
RAG_BREAKPOINT_TYPE=percentile
RAG_BREAKPOINT_AMOUNT=95
RAG_RETRIEVAL_K=5
DISTILLED_RETRIEVAL_K=3
# AutoCut post-retrieval filtering (redundant with MMR, recommend false)
AUTOCUT_ENABLED=false

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# uvicorn conf
ENV=dev
WORKERS=1


# Wikipedia Topics (comma-separated)
WIKI_TOPICS=["Artificial intelligence","Machine learning","Natural language processing","Deep learning","Neural network"]

# History Management
HISTORY_STRATEGY=sliding_window
HISTORY_MAX_MESSAGES=10
HISTORY_MAX_TOKENS=4000
HISTORY_SUMMARIZE_AFTER=8
HISTORY_SUMMARY_MAX_TOKENS=500

# LangSmith Configuration (Tracing & Observability)
# Get your API key from https://smith.langchain.com/
LANGSMITH_TRACING=false
LANGSMITH_API_KEY=
LANGSMITH_PROJECT=context-aware-rag
LANGSMITH_ENDPOINT=https://api.smith.langchain.com

# Tool Calling Configuration
# Enable LLM tool calling capabilities (retrieve_documents, web_search, clarify_query)
TOOL_CALLING_ENABLED=false
TOOL_MAX_ITERATIONS=3
TOOLS_ENABLED=retrieve_documents,web_search,clarify_query

# Web Search Configuration
# Provider options: duckduckgo (free), serpapi, tavily
WEB_SEARCH_PROVIDER=duckduckgo
WEB_SEARCH_MAX_RESULTS=5
# Optional API keys for premium search providers
SERPAPI_KEY=
TAVILY_KEY=