# Ollama Configuration
OLLAMA_MODEL=llama3.2:1b


OLLAMA_BASE_URL=http://localhost:11434 

OLLAMA_TEMPERATURE=0.7

# Vector Store Configuration
CHROMA_PERSIST_DIR=./chroma_db
CHROMA_COLLECTION_NAME=wiki_docs

# Embeddings Configuration
EMBEDDING_MODEL=BAAI/bge-small-en-v1.5
EMBEDDING_DEVICE=cpu

# RAG Configuration
RAG_BREAKPOINT_TYPE=percentile
RAG_BREAKPOINT_AMOUNT=95
RAG_RETRIEVAL_K=3

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# uvicorn conf
ENV=dev
WORKERS=1


# Wikipedia Topics (comma-separated)
WIKI_TOPICS=["Artificial intelligence","Machine learning","Natural language processing","Deep learning","Neural network"]

# History Management
HISTORY_STRATEGY=sliding_window
HISTORY_MAX_MESSAGES=10
HISTORY_MAX_TOKENS=4000
HISTORY_SUMMARIZE_AFTER=8
HISTORY_SUMMARY_MAX_TOKENS=500